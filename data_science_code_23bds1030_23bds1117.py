# -*- coding: utf-8 -*-
"""Data Science Code 23BDS1030 23BDS1117.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eYtOv_SdmBQ7-M7b54vUQ7_x4ot-sc7A
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import (roc_auc_score, average_precision_score, accuracy_score,
                             precision_score, recall_score, f1_score, brier_score_loss,
                             confusion_matrix, precision_recall_curve)
from sklearn.calibration import CalibratedClassifierCV, calibration_curve
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import shap
import joblib

!pip install fairlearn

# Fairness
from fairlearn.metrics import MetricFrame, selection_rate, false_positive_rate, true_positive_rate
from sklearn.metrics import accuracy_score

RANDOM_STATE = 42
#dataset uploading
df = pd.read_csv("heart_disease_uci.csv")

df.head()

if 'target' in df.columns:
    df['y'] = (df['target'] > 0).astype(int)
elif 'num' in df.columns:
    df['y'] = (df['num'] > 0).astype(int)
else:
    # adapt to whatever the file uses
    raise RuntimeError("Target column not found - adapt code")

# 2) Quick EDA (counts, missingness)
print(df.shape)
print(df['y'].value_counts(normalize=True))
print(df.isna().sum())

print(df.duplicated().sum())

# 3) Protected attribute(s) for fairness analysis
# UCI has 'sex' (1=male, 0=female). We'll use it as A.
if 'sex' not in df.columns:
    raise RuntimeError("sex column required for fairness examples")

A = df['sex'].copy()  # protected attribute
X = df.drop(columns=['y'])
y = df['y']

# 4) Feature engineering example: create age bins and interaction with sex
if 'age' in X.columns:
    X['age_bin'] = pd.cut(X['age'], bins=[0,40,55,65,120], labels=['<40','40-55','55-65','65+'])
    # One-hot later via ColumnTransformer

# 5) Train/test split (stratified)
X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(
    X, y, A, test_size=0.2, stratify=y, random_state=RANDOM_STATE)

X = df.drop(columns=['y', 'target', 'num'], errors='ignore')

# 6) Preprocessing pipeline
numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
# remove 'sex' from numeric features if we plan to treat as protected separately (optionally include as feature)
# numeric_features.remove('sex')  # if you want to exclude sex as feature
categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, numeric_features),
    ('cat', categorical_transformer, categorical_features)
], remainder='drop')

# 7) Model choices â€” baseline logistic, RF, XGBoost
models = {
    'logreg': LogisticRegression(max_iter=500, random_state=RANDOM_STATE),
    'rf': RandomForestClassifier(n_jobs=-1, random_state=RANDOM_STATE),
    'xgb': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)
}

# Example pipeline for XGBoost
pipe = Pipeline(steps=[('pre', preprocessor),
                       ('clf', models['xgb'])])

# 8) Hyperparameter tuning â€” RandomizedSearch with StratifiedKFold
param_dist = {
    'clf__n_estimators': [50, 100, 200],
    'clf__max_depth': [3, 4, 6, 8],
    'clf__learning_rate': [0.01, 0.05, 0.1],
    'clf__subsample': [0.6, 0.8, 1.0],
}
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)
search = RandomizedSearchCV(pipe, param_distributions=param_dist, n_iter=20,
                            scoring='roc_auc', cv=cv, random_state=RANDOM_STATE, n_jobs=-1, verbose=1)
search.fit(X_train, y_train)
print("Best params:", search.best_params_)
best_model = search.best_estimator_

pip uninstall -y xgboost

pip install xgboost==3.1.1 shap==0.49.1

# 9) Calibration (optional but recommended for clinical probability outputs)
calibrator = CalibratedClassifierCV(best_model, cv=3)
calibrator.fit(X_train, y_train)

import shap
import pandas as pd

print("Starting SHAP explainabilityâ€¦")

# 1ï¸âƒ£ Extract the trained classifier from the pipeline
xgb_model = best_model.named_steps['clf']

# 2ï¸âƒ£ Preprocess the training data using the fitted preprocessor
X_train_pre = best_model.named_steps['pre'].transform(X_train)

# 3ï¸âƒ£ Get final feature names (after encoding)
ohe = best_model.named_steps['pre'].named_transformers_['cat'].named_steps['onehot']
cat_names = list(ohe.get_feature_names_out(categorical_features))
feature_names = numeric_features + cat_names
X_train_pre_df = pd.DataFrame(X_train_pre, columns=feature_names)

# 4ï¸âƒ£ Define a prediction function (required by KernelExplainer)
f = lambda x: xgb_model.predict_proba(x)[:, 1]

# 5ï¸âƒ£ Initialize the SHAP KernelExplainer with a sample of the training data
# (using a subset keeps runtime manageable)
explainer = shap.KernelExplainer(f, X_train_pre_df.sample(100, random_state=42))

# 6ï¸âƒ£ Compute SHAP values for a few samples (to avoid long computation time)
X_sample = X_train_pre_df.sample(10, random_state=42)
shap_values = explainer.shap_values(X_sample)

# 7ï¸âƒ£ Global feature importance summary plot
shap.summary_plot(shap_values, X_sample, feature_names=feature_names, show=True)

# Example: local SHAP explanation for one sample
i = 3  # choose an observation
shap.force_plot(
    explainer.expected_value,
    shap_values[i, :],
    X_sample.iloc[i, :],
    matplotlib=True,
    show=True
)

import shap
shap.initjs()  # enables interactive visualization

i = 3  # sample index

# Interactive local explanation (works in Jupyter/Colab)
shap.force_plot(
    explainer.expected_value,
    shap_values[i, :],
    X_sample.iloc[i, :],
)

# 14) Fairness evaluation before mitigation
# MetricFrame to compute metrics by protected group
y_pred_raw = calibrator.predict(X_test)  # discrete predictions
metric_frame = MetricFrame(metrics={'accuracy': accuracy_score,
                                    'selection_rate': selection_rate,
                                    'fpr': false_positive_rate,
                                    'tpr': true_positive_rate},
                           y_true=y_test, y_pred=y_pred_raw, sensitive_features=A_test)
print(metric_frame.by_group)
print("Overall metric diffs:", metric_frame.difference())

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)
plt.show()

from sklearn.metrics import RocCurveDisplay
RocCurveDisplay.from_estimator(best_model, X_test, y_test)
plt.show()

from sklearn.metrics import PrecisionRecallDisplay
PrecisionRecallDisplay.from_estimator(best_model, X_test, y_test)
plt.show()

metric_frame.by_group.plot.bar(figsize=(8,5))
plt.title("Fairness Metrics by Gender (Sex)")
plt.ylabel("Metric Value")
plt.show()

from fairlearn.reductions import ExponentiatedGradient, DemographicParity
from sklearn.linear_model import LogisticRegression

# 1ï¸âƒ£ Recreate the constraint object fresh
constraint = DemographicParity()

# 2ï¸âƒ£ Initialize the mitigator again
mitigator = ExponentiatedGradient(
    estimator=LogisticRegression(max_iter=1000, solver='liblinear'),
    constraints=constraint
)

# 3ï¸âƒ£ Train with fairness constraint
mitigator.fit(X_train_pre, y_train, sensitive_features=A_train)

# 4ï¸âƒ£ Predict
y_pred_fair = mitigator.predict(X_test_pre)

# 7ï¸âƒ£ Evaluate fairness metrics
metric_frame_fair = MetricFrame(
    metrics={
        'accuracy': accuracy_score,
        'selection_rate': selection_rate,
        'fpr': false_positive_rate,
        'tpr': true_positive_rate
    },
    y_true=y_test,
    y_pred=y_pred_fair,
    sensitive_features=A_test
)

print("=== Fairness metrics AFTER mitigation ===")
print(metric_frame_fair.by_group)
print("Differences between groups:")
print(metric_frame_fair.difference())

fig, ax = plt.subplots(1, 2, figsize=(12, 5))

metric_frame.by_group[['accuracy', 'selection_rate']].plot.bar(ax=ax[0])
ax[0].set_title("Before Fairness Mitigation")

metric_frame_fair.by_group[['accuracy', 'selection_rate']].plot.bar(ax=ax[1])
ax[1].set_title("After Fairness Mitigation")

plt.tight_layout()
plt.show()

import joblib

# Save the full pipeline (preprocessing + classifier)
joblib.dump(best_model, "heart_disease_model.pkl")

print("âœ… Model saved successfully as 'heart_disease_model.pkl'")

!pip install streamlit ngrok

!pip install streamlit pyngrok

from pyngrok import ngrok
import joblib

# Save your existing trained model from Colab
joblib.dump(best_model, "heart_model.pkl")
print("âœ… Model saved successfully.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# import joblib
# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve
# 
# # -----------------------------
# # 1ï¸âƒ£ Load Model
# # -----------------------------
# model = joblib.load("heart_model.pkl")
# 
# st.set_page_config(page_title="Heart Disease Prediction", layout="wide")
# st.title("â¤ï¸ Heart Disease Prediction Dashboard")
# 
# st.write("""
# This dashboard uses your trained ML model to predict **Heart Disease Risk**
# and visualize **model performance and insights**.
# """)
# 
# # -----------------------------
# # 2ï¸âƒ£ Sidebar - Patient Inputs
# # -----------------------------
# st.sidebar.header("Enter Patient Details")
# 
# age = st.sidebar.slider("Age", 20, 80, 50)
# sex = st.sidebar.radio("Sex", ["Male", "Female"])
# cp = st.sidebar.selectbox("Chest Pain Type", ["typical angina","atypical angina","non-anginal pain","asymptomatic"])
# trestbps = st.sidebar.slider("Resting BP (mm Hg)", 80, 200, 120)
# chol = st.sidebar.slider("Cholesterol (mg/dl)", 100, 600, 200)
# fbs = st.sidebar.radio("Fasting Blood Sugar > 120 mg/dl", ["Yes","No"])
# restecg = st.sidebar.selectbox("Resting ECG", ["normal","ST-T abnormality","left ventricular hypertrophy"])
# thalach = st.sidebar.slider("Max Heart Rate", 60, 220, 150)
# exang = st.sidebar.radio("Exercise Induced Angina", ["Yes","No"])
# oldpeak = st.sidebar.slider("ST Depression", 0.0, 6.0, 1.0)
# slope = st.sidebar.selectbox("Slope", ["upsloping","flat","downsloping"])
# ca = st.sidebar.slider("Major Vessels (0â€“3)", 0, 3, 0)
# thal = st.sidebar.selectbox("Thalassemia", ["normal","fixed defect","reversible defect"])
# 
# # -----------------------------
# # 3ï¸âƒ£ Prepare Input DataFrame
# # -----------------------------
# df = pd.DataFrame({
#     'age':[age],
#     'sex':[1 if sex=='Male' else 0],
#     'cp':[cp],
#     'trestbps':[trestbps],
#     'chol':[chol],
#     'fbs':[1 if fbs=='Yes' else 0],
#     'restecg':[restecg],
#     'thalach':[thalach],
#     'exang':[1 if exang=='Yes' else 0],
#     'oldpeak':[oldpeak],
#     'slope':[slope],
#     'ca':[ca],
#     'thal':[thal]
# })
# 
# # -----------------------------
# # 4ï¸âƒ£ Handle Missing Columns
# # -----------------------------
# expected_cols = model.named_steps['pre'].feature_names_in_
# for col in expected_cols:
#     if col not in df.columns:
#         df[col] = 0
# df = df[expected_cols]
# 
# # -----------------------------
# # 5ï¸âƒ£ Prediction
# # -----------------------------
# if st.button("ðŸ” Predict"):
#     prob = model.predict_proba(df)[0,1]
#     pred = "â¤ï¸ High Risk of Heart Disease" if prob > 0.5 else "ðŸ’š Low Risk of Heart Disease"
# 
#     st.subheader("Prediction Result")
#     st.metric(label="Predicted Probability", value=f"{prob:.2f}")
#     if prob > 0.5:
#         st.error(pred)
#     else:
#         st.success(pred)
# 
# # -----------------------------
# # 6ï¸âƒ£ Model Performance Section
# # -----------------------------
# st.markdown("---")
# st.header("ðŸ“Š Model Performance Insights")
# 
# # Load test data metrics (optional pre-computed in Colab)
# try:
#     y_test = np.load("y_test.npy")
#     X_test = joblib.load("X_test.pkl")
#     y_pred = model.predict(X_test)
# 
#     acc = accuracy_score(y_test, y_pred)
#     prec = precision_score(y_test, y_pred)
#     rec = recall_score(y_test, y_pred)
#     f1 = f1_score(y_test, y_pred)
# 
#     col1, col2, col3, col4 = st.columns(4)
#     col1.metric("Accuracy", f"{acc:.2f}")
#     col2.metric("Precision", f"{prec:.2f}")
#     col3.metric("Recall", f"{rec:.2f}")
#     col4.metric("F1 Score", f"{f1:.2f}")
# 
#     # Confusion Matrix
#     st.subheader("Confusion Matrix")
#     cm = confusion_matrix(y_test, y_pred)
#     fig, ax = plt.subplots()
#     sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['No Disease', 'Disease'], yticklabels=['No Disease', 'Disease'])
#     plt.xlabel("Predicted")
#     plt.ylabel("Actual")
#     st.pyplot(fig)
# 
#     # ROC Curve
#     st.subheader("ROC Curve")
#     fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])
#     roc_auc = auc(fpr, tpr)
#     fig2, ax2 = plt.subplots()
#     ax2.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.2f})')
#     ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
#     ax2.set_xlabel('False Positive Rate')
#     ax2.set_ylabel('True Positive Rate')
#     ax2.legend()
#     st.pyplot(fig2)
# 
#     # Precision-Recall Curve
#     st.subheader("Precision-Recall Curve")
#     prec_curve, rec_curve, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])
#     fig3, ax3 = plt.subplots()
#     ax3.plot(rec_curve, prec_curve, color='green')
#     ax3.set_xlabel('Recall')
#     ax3.set_ylabel('Precision')
#     st.pyplot(fig3)
# 
#     # Feature Importance
#     st.subheader("Feature Importance (from XGBoost)")
#     clf = model.named_steps['clf']
#     importance = clf.get_booster().get_score(importance_type='weight')
#     if importance:
#         importance_df = pd.DataFrame({'Feature': list(importance.keys()), 'Importance': list(importance.values())}).sort_values(by='Importance', ascending=False)
#         st.bar_chart(importance_df.set_index('Feature'))
# 
#     # Fairness Snapshot
#     st.subheader("Fairness Snapshot by Gender")
#     if 'sex' in X_test.columns:
#         male_prob = model.predict_proba(X_test[X_test['sex']==1])[:,1].mean()
#         female_prob = model.predict_proba(X_test[X_test['sex']==0])[:,1].mean()
#         st.write(f"**Avg Predicted Risk (Male):** {male_prob:.2f}")
#         st.write(f"**Avg Predicted Risk (Female):** {female_prob:.2f}")
# 
# except Exception as e:
#     st.info("Performance metrics unavailable. (Optional: Save X_test and y_test for dashboard visualization.)")
# 
# st.markdown("---")
# st.caption("Built in Colab using Streamlit, XGBoost, and scikit-learn.")
#

!ngrok config add-authtoken 357CkSLGLN9OVRqPYShk2cwDIf7_6UYY1SLhrG7ofxXsRk82G

# Run Streamlit and create public link
public_url = ngrok.connect(8501)
print("Public URL:", public_url)
!streamlit run app.py --server.port 8501 &>/dev/null &